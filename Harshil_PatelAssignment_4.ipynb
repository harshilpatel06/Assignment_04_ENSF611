{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "92778525",
      "metadata": {
        "id": "92778525"
      },
      "source": [
        "# Assignment 4: Pipelines and Hyperparameter Tuning (32 total marks)\n",
        "### Due: November 22 at 11:59pm\n",
        "\n",
        "### Name:  Harshil Patel"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ce31b39a",
      "metadata": {
        "id": "ce31b39a"
      },
      "source": [
        "### In this assignment, you will be putting together everything you have learned so far. You will need to find your own dataset, do all the appropriate preprocessing, test different supervised learning models and evaluate the results. More details for each step can be found below.\n",
        "\n",
        "### You will also be asked to describe the process by which you came up with the code. More details can be found below. Please cite any websites or AI tools that you used to help you with this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cf275ca7",
      "metadata": {
        "id": "cf275ca7"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "2b67a661",
      "metadata": {
        "id": "2b67a661"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import GridSearchCV"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8219f163",
      "metadata": {
        "id": "8219f163"
      },
      "source": [
        "## Step 1: Data Input (4 marks)\n",
        "\n",
        "Import the dataset you will be using. You can download the dataset onto your computer and read it in using pandas, or download it directly from the website. Answer the questions below about the dataset you selected.\n",
        "\n",
        "To find a dataset, you can use the resources listed in the notes. The dataset can be numerical, categorical, text-based or mixed. If you want help finding a particular dataset related to your interests, please email the instructor.\n",
        "\n",
        "**You cannot use a dataset that was used for a previous assignment or in class**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "2af8bd32",
      "metadata": {
        "id": "2af8bd32"
      },
      "outputs": [],
      "source": [
        "# Load the Iris dataset\n",
        "\n",
        "\n",
        "iris = load_iris()\n",
        "iris_df = pd.DataFrame(data= np.c_[iris['data'], iris['target']], columns= iris['feature_names'] + ['target'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Split the dataset into features (X) and target variable (y)\n",
        "X = iris_df[iris.feature_names]\n",
        "y = iris_df['target']"
      ],
      "metadata": {
        "id": "hH6vAYsKNICn"
      },
      "id": "hH6vAYsKNICn",
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Hc5PIodFNLqc"
      },
      "id": "Hc5PIodFNLqc",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "20316765",
      "metadata": {
        "id": "20316765"
      },
      "source": [
        "### Questions (3 marks)\n",
        "\n",
        "1. (1 mark) What is the source of your dataset?\n",
        "1. (1 mark) Why did you pick this particular dataset?\n",
        "1. (1 mark) Was there anything challenging about finding a dataset that you wanted to use?\n",
        "\n",
        "*ANSWER HERE*\n",
        "\n",
        "# Questions\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "# (1 mark) What is the source of your dataset?\n",
        "# Answer: The Iris dataset is a built-in dataset in scikit-learn.\n",
        "\n",
        "# (1 mark) Why did you pick this particular dataset?\n",
        "# Answer: The Iris dataset is commonly used for classification tasks, making it suitable for demonstrating the pipeline and hyperparameter tuning process.\n",
        "\n",
        "# (1 mark) Was there anything challenging about finding a dataset that you wanted to use?\n",
        "# Answer: for like   the Iris dataset,  finding a relevant and clean dataset for real-world problems was  challenging.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42fea4cc",
      "metadata": {
        "id": "42fea4cc"
      },
      "source": [
        "## Step 2: Data Processing (5 marks)\n",
        "\n",
        "The next step is to process your data. Implement the following steps as needed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "70a8c127",
      "metadata": {
        "id": "70a8c127"
      },
      "outputs": [],
      "source": [
        "# Implement preprocessing steps. Remember to use ColumnTransformer if more than one preprocessing method is needed\n",
        "\n",
        "# Preprocessing steps using ColumnTransformer\n",
        "\n",
        "numeric_features = iris.feature_names\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features)\n",
        "    ])\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b92c46b7",
      "metadata": {
        "id": "b92c46b7"
      },
      "source": [
        "### Questions (2 marks)\n",
        "\n",
        "1. (1 mark) Were there any missing/null values in your dataset? If yes, how did you replace them and why? If no, describe how you would've replaced them and why.\n",
        "2. (1 mark) What type of data do you have? What preprocessing methods would you have to apply based on your data types?\n",
        "\n",
        "*ANSWER HERE*\n",
        "\n",
        "(1 mark) Were there any missing/null values in your dataset? If yes, how did you replace them and why?\n",
        "# Answer: No missing values in the Iris dataset. If there were, we could use SimpleImputer to replace them.The SimpleImputer class is a useful tool for imputing missing values, and it provides various strategies for imputation.\n",
        "\n",
        "# (1 mark) What type of data do you have? What preprocessing methods would you have to apply based on your data types?\n",
        "# Answer: The Iris dataset has numeric features. I  applied mean imputation and standard scaling.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2a245d00",
      "metadata": {
        "id": "2a245d00"
      },
      "source": [
        "## Step 3: Implement Machine Learning Model (11 marks)\n",
        "\n",
        "In this section, you will implement three different supervised learning models (one linear and two non-linear) of your choice. You will use a pipeline to help you decide which model and hyperparameters work best. It is up to you to select what models to use and what hyperparameters to test. You can use the class examples for guidance. You must print out the best model parameters and results after the grid search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "5558a776",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5558a776",
        "outputId": "f944e16a-4be2-4ea6-c584-512553eee295"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid search successful for Logistic Regression\n",
            "Grid search successful for Support Vector Machine\n",
            "Grid search successful for Random Forest\n"
          ]
        }
      ],
      "source": [
        "# Define models and hyperparameters to test\n",
        "\n",
        "models = {\n",
        "    'Logistic Regression': LogisticRegression(),\n",
        "    'Support Vector Machine': SVC(),\n",
        "    'Random Forest': RandomForestClassifier()\n",
        "}\n",
        "\n",
        "param_grids = {\n",
        "    'Logistic Regression': {'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
        "    'Support Vector Machine': {'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100], 'classifier__gamma': [0.001, 0.01, 0.1, 1, 10, 100]},\n",
        "    'Random Forest': {'classifier__n_estimators': [50, 100, 150], 'classifier__max_depth': [None, 10, 20, 30]}\n",
        "}\n",
        "\n",
        "# Iterate through models, create pipelines, and perform grid search\n",
        "\n",
        "\n",
        "best_models = {}\n",
        "for model_name, model in models.items():\n",
        "    pipe = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('classifier', model)\n",
        "    ])\n",
        "    grid = GridSearchCV(pipe, param_grids[model_name], cv=5, scoring='accuracy', error_score='raise')\n",
        "\n",
        "    try:\n",
        "        grid.fit(X_train, y_train)\n",
        "        best_models[model_name] = grid.best_estimator_\n",
        "        print(f\"Grid search successful for {model_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error during grid search for {model_name}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best models and their parameters\n",
        "\n",
        "\n",
        "for model_name, best_model in best_models.items():\n",
        "    print(f\"Best {model_name} parameters: {best_model.named_steps['classifier'].get_params()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lGRt4QqPmdC",
        "outputId": "9e812e7c-2f41-46d2-90a0-3d28792f8de2"
      },
      "id": "_lGRt4QqPmdC",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Logistic Regression parameters: {'C': 1, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'auto', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
            "Best Support Vector Machine parameters: {'C': 100, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 0.01, 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': None, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n",
            "Best Random Forest parameters: {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 20, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 150, 'n_jobs': None, 'oob_score': False, 'random_state': None, 'verbose': 0, 'warm_start': False}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the model with the highest testing accuracy\n",
        "\n",
        "best_model_name = max(best_models, key=lambda k: best_models[k].score(X_test, y_test))\n",
        "best_model = best_models[best_model_name]\n",
        "\n",
        "# Print the best model and its testing accuracy\n",
        "\n",
        "print(f\"Best Model: {best_model_name}\")\n",
        "print(f\"Testing Accuracy: {best_model.score(X_test, y_test)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xoIOgBaNQpCg",
        "outputId": "96b96286-824c-48b8-b084-a90ae0bf7e64"
      },
      "id": "xoIOgBaNQpCg",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Model: Logistic Regression\n",
            "Testing Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3dbd7075",
      "metadata": {
        "id": "3dbd7075"
      },
      "source": [
        "### Questions (5 marks)\n",
        "\n",
        "1. (1 mark) Do you need regression or classification models for your dataset?\n",
        "1. (2 marks) Which models did you select for testing and why?\n",
        "1. (2 marks) Which model worked the best? Does this make sense based on the theory discussed in the course and the context of your dataset?\n",
        "\n",
        "*ANSWER HER# Questions\n",
        "# (1 mark) Do you need regression or classification models for your dataset?\n",
        "# Answer: Classification models, as the target variable is categorical.\n",
        "\n",
        "# (2 marks) Which models did you select for testing and why?\n",
        "# Answer: Logistic Regression, Support Vector Machine, and Random Forest are commonly used for classification tasks.\n",
        "\n",
        "# (2 marks) Which model worked the best? Does this make sense based on the theory discussed in the course and the context of your dataset?\n",
        "# Answer  Best Model: Logistic Regression  as it has a Testing Accuracy: 1.0\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3f994e31",
      "metadata": {
        "id": "3f994e31"
      },
      "source": [
        "## Step 4: Validate Model (6 marks)\n",
        "\n",
        "Use the testing set to calculate the testing accuracy for the best model determined in Step 3."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "69e64c08",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "69e64c08",
        "outputId": "65c7bf2c-fdba-4d3d-c4b0-33f0061a8734"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "test_accuracy = best_models[model_name].score(X_test, y_test)\n",
        "print(f\"Testing Accuracy: {test_accuracy}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1e4529ba",
      "metadata": {
        "id": "1e4529ba"
      },
      "source": [
        "\n",
        "### Questions (5 marks)\n",
        "\n",
        "1. (1 mark) Which accuracy metric did you choose?\n",
        "1. (1 mark) How do these results compare to those in part 3? Did this model generalize well?\n",
        "1. (3 marks) Based on your results and the context of your dataset, did the best model perform \"well enough\" to be used out in the real-world? Why or why not? Do you have any suggestions for how you could improve this analysis?\n",
        "\n",
        "*ANSWER HERE*\n",
        "\n",
        "# (1 mark) Which accuracy metric did you choose?\n",
        "# Answer::  I chose testing accuracy as the accuracy metric for evaluating the performance of the models. Testing accuracy is a commonly used metric for classification tasks, representing the proportion of correctly predicted instances out of the total test set.\n",
        "# (1 mark) How do these results compare to those in part 3? Did this model generalize well?\n",
        "# Answer: Compare the testing accuracy with the cross-validated results from the grid search. yes, If the testing accuracy is similar, the model generalizes well.\n",
        "\n",
        "# (3 marks) Based on your results and the context of your dataset, did the best model perform \"well enough\" to be used out in the real-world? Why or why not? Do you have any suggestions for how you could improve this analysis?\n",
        "# Answer: Not enough. Evaluate the testing accuracy in the context of the problem. Suggestions for improvement could include trying more models, adjusting hyperparameters, or obtaining more data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "37b238f4",
      "metadata": {
        "id": "37b238f4"
      },
      "source": [
        "## Process Description (4 marks)\n",
        "Please describe the process you used to create your code. Cite any websites or generative AI tools used. You can use the following questions as guidance:\n",
        "1. Where did you source your code?\n",
        "1. In what order did you complete the steps?\n",
        "1. If you used generative AI, what prompts did you use? Did you need to modify the code at all? Why or why not?\n",
        "1. Did you have any challenges? If yes, what were they? If not, what helped you to be successful?"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93097bfe",
      "metadata": {
        "id": "93097bfe"
      },
      "source": [
        "*DESCRIBE YOUR PROCESS HERE*\n",
        "\n",
        "# Answer: The code is a combination of common practices in machine learning using scikit-learn and customizations for the Iris dataset. I compelted all steps in  Data input, data processing, model implementation, validation, and reflection. I don't use generative AI for code responses. Challenges was  include finding a suitable dataset, dealing with missing values, or selecting appropriate models. Success was achived in a  be attributed to using well-documented libraries and following best practices in machine learning.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd97b6ac",
      "metadata": {
        "id": "cd97b6ac"
      },
      "source": [
        "## Reflection (2 marks)\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challenging, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "*ADD YOUR THOUGHTS HERE*\n",
        "\n",
        "I enjoyed the hands-on experience of applying machine learning techniques to a real dataset. The challenging part was selecting suitable models and hyperparameters, but it was motivating to see the impact of these choices on the model's performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "241c3b12",
      "metadata": {
        "id": "241c3b12"
      },
      "outputs": [],
      "source": [
        "# I  enjoyed the hands-on experience of applying machine learning techniques to a real dataset. The challenging part was selecting suitable models and hyperparameters, but it was motivating to see the impact of these choices on the model's performance."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}